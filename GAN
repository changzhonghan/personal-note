pix2pix
dualGAN
cycleGAN
DIscoGAn

text 2 image
Generative Adversarial Text to Image Synthesis
StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Network

pix2pix 
https://arxiv.org/pdf/1611.07004v1.pdf
http://m.blog.csdn.net/article/details?id=53284559
https://zhuanlan.zhihu.com/p/25000523?refer=dlclass

[0]

    生成对抗网络（GAN：Generative Adversarial Networks）
        GAN启发自博弈论中的二人零和博弈，由[Goodfellow et al, NIPS 2014]开创性地提出，包含一个生成模型（generative model G）和一个判

别模型（discriminative model D）。生成模型捕捉样本数据的分布，判别模型是一个二分类器，判别输入是真实数据还是生成的样本。这个模型的优

化过程是一个“二元极小极大博弈（minimax two-player game）”问题，训练时固定一方，更新另一个模型的参数，交替迭代，使得对方的错误最大化

，最终，G 能估测出样本数据的分布。
    变分自编码器（VAE: Variational Autoencoders）
        在概率图形模型（probabilistic graphical models ）的框架中对这一问题进行形式化——在概率图形模型中，我们在数据的对数似然上最大

化下限（lower bound）。
    自回归模型（Autoregressive models）
        PixelRNN 这样的自回归模型则通过给定的之前的像素（左侧或上部）对每个单个像素的条件分布建模来训练网络。这类似于将图像的像素插入 

char-rnn 中，但该 RNN 在图像的水平和垂直方向上同时运行，而不只是字符的 1D 序列。




[0]
GAN是如何工作的？
原始图
[0]
GAN是如何工作的？
黄色的图
http://www.w2bc.com/article/197155


[1]
生成器  z>>x
使用pz表示输入噪声的后验概率
使用G表示生成器的映射方程
生成器的分布pg
生成器使用神经网络实现

判别器  D(x)>>0-1
使用神经网络构建D
D(x)表示x来自真实数据的可能性
判别器的输出为标量

[2]
方程(1)
生成器和判决器进行minimax博弈
生成器用于生成伪数据,欺骗判别器
判别器用于判别输入是否来自真实数据
生成器和判别器同步训练

[3]
figure 1 a

生成对抗网络训练过程中,同步训练生成器和判别器
生成器不断更新pg拟合pdata
判决器同步更新,判断数据是否来自pg

[4]
figure bcd
迭代中，判别器被训练用于识别数据真伪，并最终收敛
更新生成器的过程中，来自判别器的梯度指导映射G逼近真实数据
经过多次迭代训练，G和D用足够的学习能力，系统最终收敛：pg=pdata d = 1/2


[5]
训练过程
进入循环体，迭代N次
  进入循环体，迭代k次
     根据噪声分布pz，采样噪声数据
     根据样本分布pdatax，采样真实数据
     使用随机梯度下降更新判别器
  根据噪声分布pz，采样噪声数据
  使用随机梯度下降更新生成器


[6]理论验证
命题1 当生成器G固定时，判别器的理想解为：

证明：对于任意更定的生成器G，判别器的作用为最大化V
v= 
[7]
判别器D的优化目标是使田间概率p(y=y|x)最大
x：表示输入判别器的数据，可能来自真实样本或生成器
y：x是否来自真实数据
minimax游戏可以表示为：方程4

[8]
 定理 1
当cg成立时，当且仅当存在pg=pdata
证明：通过化简CG得到：
CD=。。

其中，KL散度( Kullback–Leibler divergence)，又称相对熵（relative entropy)，
当且仅当 pg=pdata时，cg取得最小值

[9]算法收敛
证明. 如上述标准考虑V(G,D)=U(pg,D)为关于pg的函数。注意到U(pg,D)为pg的凸函数。该凸函数上确界的一次导数包括达到最大值处的该函数的导数。

换句话说，如果f(x)=supα∈Afα(x)，且对每个α，fα(x)关于x是凸的，那么如果β=arg1supα∈Afα(x)，则?fβ(x)∈?f。等价于给定对应的G和最

优判别D，梯度下降更新pg。在定理 1 中证明supDU(pg,D)关于pg是凸的且有唯一的全局最优解，因此，pg更新足够小时，pg收敛到px，证毕。

[10]试验
使用了MNIST手写字符数据集
Toronto Face Database数据集
CIFAR-10数据集


[11]使用了Gaussian Parzen window计算生成样本的似然度
使用测试集进行交叉验证，计算6


[12]
7. 结论与未来工作

该框架允许许多直接的扩展：
1) 添加c至G和D的输入，可获得条件的生成模型p(x|c)。
2) 给定x，为预测z，训练任意的网络可学习近似推理。类似于 wake-sleep 算法训练出的推理网络，但训练推理网络时可能要用到训练完成后的固定的

生成网络。
3) 来近似建模所有的条件概率P(xS|x?S)，其中，S为通过训练共享参数的条件模型簇的x的索引。本质上，对抗的网络可用于随机扩展 MP-DBM。
4) 半监督学习：当标签数据有限时，判别网络或推理网络的特征不会提高分类器效果。
5) 效率改善：为协调G和D设计更好的方法，或训练期间确定更好的分布来采样z，从而加速训练。
(1) 将GAN改进为条件产生式模型：这一点最早在GAN公开后的半年就得到了部分解决，即conditional GAN（ARXIV-2014）的工作，该模型实现了给定条

件的数据生成，但现在在各个领域特别是图像和视频相关的生成工作中，也依然有许多对于给定条件生成数据的任务的相关改进与研究；

(2) 改进输入z：不直接用随机噪声信号，而是可以用其它网络根据真实数据x学习一个z，然后再输入G，相当于是对数据x做了一个编码；这一点目前基

本上在多数基于GAN的应用中都被采纳；

(3) 对条件分布建模，由已有数据预测未出现的数据：往这个方向改进的相关工作相对出现较晚，直到2016年才逐步开始有相关工作出现；

(4) 半监督学习：在2015年年底出现了将GAN用于半监督问题的工作；另外，现有的许多GAN工作也都表明通过加入少量类别标签，引入有标签数据的类别

损失度量，不仅功能上实现了半监督学习，同时也有助于GAN的稳定训练；

(5) 提升GAN的训练效率：目前比GAN的训练效率更加要紧的训练稳定性问题还没有得到很好的解决，因此相对来说，目前这一点的研究并不广泛，而且相

比较其它的产生式模型而言，GAN的速度也不算是一个非常“拖后腿”的点。




deepface：


在DeepFace论文中，只使用CNN对图像提取特征完成人脸校验。DeepFace在训练神经网络前，使用了对齐方法，论文中认为在使用人连对齐之后，人脸的局部特征会固定在特定区域，可以直接使用卷及神经网络从对齐图像中提取特征。
DeepFace主要解决的问题包括:提出了一个适合人脸表征的深度神经网络结构；提出了一个快速且有效的3D人脸对齐方法，提升了系统的效果；在多个公开数据实现了很好的效果。

脸对齐流程中，首先使用了2D对齐，提取六个特征点并对图像进行拉伸处理。重复进行2D对齐可以有效实现人脸对齐。为了处理轴外偏移，在3D对齐中提取67个基准点，并进行图像对齐。为了完成人脸校验功能，论文使用了Weighted χ2 distance进行校验度量和Siamses网络用于图像的身份验证。


卷及神经网络直接处理原始图像，网络输入为152*152*3。网络的前两层为11*11卷积核（32通道）的卷积层和池化层。然后，经过9×9的卷积核处理得到全局特征。网络中使用了局部卷积的方式，提取局部特征。其中，由于区域具有不同的统计特在，在局部卷积层中，卷积核不是共享的。最后，特征经过全连接层和softmax分类器输出。
论文使用了SFC数据集对网络进行了训练,并在LFW数据集和YTF数据集进行了测试，性能优于传统方法。论文指出，卷积神经网络可以构建一个人脸识别系统，并且不会因为光照，姿态，图像质量等不确定因素影响性能。


DeepID

DeepID可以有效地实现人脸识别任务，同时对人脸校验等也具有很好的通用性。训练二进制分类器实现超多类识别任务效果不佳，论文提出，使用卷积神经网络可以提取具有表征能力的特征，使用多个网络分别处理图像的局部区域，并将特征用于实现10000类身份识别。DeepID中提出的卷积神经网络输入为39*39的图像，包括多个卷积层和池化层，用于提取特征表示的DeepID隐藏层包括160个神经元，最后输出层神经元数目与类别数量相同。论文中，首先针对图像提取了五个特征点并进行了对齐，并训练了60个CNN分别对10个特定区域，3种不同的尺度，RGB通道和灰度图像提取特征，并进行水平翻转后再次提取特征，最终得到160*2*60维特征。使用 Joint Bayesian处理DeepID特征完成身份校验（Face verification）。

DeepID2
DeepID2延续了DeepID的主要思想：设计一个特征表示方法，可以减小类内间隔，同时类间间隔最大。卷积神经网络的设计与第一代有所不同,网络中使用了四个卷积层,其中第3/4层使用了局部卷积。全连接层与第三层和第四层连接，可以提取不同尺度的特征，并输出160维特征。网络的训练过程同时考虑到了人脸鉴定和人脸检验，代价函数包括交互熵和类间/类内距离。试验中使用了LFWCelebFaces和数据集，论文讨论了多目标代价函数的权值，训练集的大小对性能的影响，用于校验任务的目标函数选择。

在DeepID2++和DeepID3中，作者尝试了将网络深度加深的思路。DeepID3中提出了两种网络结构,参考了VGGnet和GoogLeNet的设计。网络参考了VGGnet的堆叠多层卷积核的思路，并且在网络中部添加全连接层作为分支输出，提高网络中间层的识别能力。最顶层的卷积层使用了局部卷积提取图像的局部特征。论文涉及了两种网络结构，net1中没有使用inception层，并将局部卷积的结果作为特征输出；net2中使用了inception层，并在顶层的局部卷积层的基础上添加了全连接层。论文分别进行了人脸鉴别实验和人脸校验实验，性能相对于上一代DeepID++有所提升。

FaceNets
与其他用于人脸识别的深度学习方法不同，FaceNet没有使用传统的softmax的方式去进行分类学习，然后抽取其中某一层作为特征。facenet直接使用了一种端对端的学习方式，实现了从图像到欧式空间的编码，然后基于这个编码实现人脸识别、人脸验证和人脸聚类等。
FaceNet使用了深度卷积神经网络处理图像，并使用了L2归一化将特征映射到R维欧式空间。在欧式空间中同一个人多张的照片的距离小于本人照片他人照片的距离，论文采用了Triplet loss作为代价函数，减小欧式空间中相同身份的样本的距离，同时最大化非同类样本的欧式距离。
论文使用了ZFnet和GoogLenet进行实验，谈论了网络模型,训练集合,特征维度和图片质量对实验结果的影响，实验证明：提取特征直接计算距离，比之前的使用 PCA + SVM 更加简单，使用端到端的方式训练网络都可以提高算法的准确度。


当前用于人脸识别任务的深度学习模型中，网络的深度和宽度逐渐增加，如何减少网络参数并保持网络的性能十分重要。






LFW

LFW数据库主要用于研究人脸识别问题,图像包括13000张网络收集的人脸照片,每张照片都有一个对应的姓名标签，训练集和测试集的人员身份是完全不重叠的。LFW数据集主要用于处理自然环境下的人脸识别问题。主要问题包括人脸校验和人脸匹配。在人脸校验任务中，提供一组包括人物身份的训练集，针对无标签的测试集，给出每张图片的真实身份。在人脸匹配任务中，系统需要处理两张图像，并判断是否来自同一志愿者。LFWA数据集是在已有的图像基础上，添加了5个特征点位置信息和40种二进制表示的属性标签。



CelebFaces Attributes Dataset

CelebA数据集包括200K张名人照片，每张图片由40个属性标签。图像内容涵盖了大量的姿态变化和不同背景。CelebA数据集包括10177名不同人士202599张图片，其中包括了5个特征点信息和40种二进制表示的属性标签。

MegaFace


